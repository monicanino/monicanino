{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XebDJ3UnS3n3"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_-HjrL6S3n5"
   },
   "source": [
    "# Lab 5.3.1 \n",
    "# *Support Vector Machines*\n",
    "\n",
    "SVMs use linear algebra to find an (n-1)-dimensional boundary that separates classes within an n-dimensional space. In practical terms, this technique provides a conceptually simple way to predict class membership from a set of features. \n",
    "\n",
    "The standard (linear) SVM is immediately applicable to linear classification problems. Furthermore, by applying transformations to the feature space it is possible to tackle nonlinear classificaiton problems. These transforms are called *kernels*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azVVNUxHYKej"
   },
   "source": [
    "### 1. Load Data\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1) ID number 2) Diagnosis (M = malignant, B = benign) 3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter) b) texture (standard deviation of gray-scale values) c) perimeter d) area e) smoothness (local variation in radius lengths) f) compactness (perimeter^2 / area - 1.0) g) concavity (severity of concave portions of the contour) h) concave points (number of concave portions of the contour) i) symmetry j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "All feature values are recoded with four significant digits.\n",
    "\n",
    "Missing attribute values: none\n",
    "\n",
    "Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:13:16.458182Z",
     "start_time": "2019-05-09T05:13:16.454244Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aICmn_7xYKek"
   },
   "outputs": [],
   "source": [
    "breast_cancer_csv = pd.read_csv('../../DATA/breast-cancer-wisconsin-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPRqG96QYKen"
   },
   "source": [
    "### 2. EDA \n",
    "\n",
    "- Explore dataset. Clean data (if required)\n",
    "- Find features to predict class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_csv.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074626</td>\n",
       "      <td>0.099770</td>\n",
       "      <td>0.073159</td>\n",
       "      <td>0.096893</td>\n",
       "      <td>-0.012968</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.050080</td>\n",
       "      <td>0.044158</td>\n",
       "      <td>-0.022114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064720</td>\n",
       "      <td>0.079986</td>\n",
       "      <td>0.107187</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>-0.002968</td>\n",
       "      <td>0.023203</td>\n",
       "      <td>0.035174</td>\n",
       "      <td>-0.044224</td>\n",
       "      <td>-0.029866</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>0.074626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.170581</td>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.147741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297008</td>\n",
       "      <td>0.965137</td>\n",
       "      <td>0.941082</td>\n",
       "      <td>0.119616</td>\n",
       "      <td>0.413463</td>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.163953</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>0.099770</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.329533</td>\n",
       "      <td>0.321086</td>\n",
       "      <td>-0.023389</td>\n",
       "      <td>0.236702</td>\n",
       "      <td>0.302418</td>\n",
       "      <td>0.293464</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912045</td>\n",
       "      <td>0.358040</td>\n",
       "      <td>0.343546</td>\n",
       "      <td>0.077503</td>\n",
       "      <td>0.277830</td>\n",
       "      <td>0.301025</td>\n",
       "      <td>0.295316</td>\n",
       "      <td>0.105008</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>0.073159</td>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.329533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.207278</td>\n",
       "      <td>0.556936</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.183027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303038</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>0.941550</td>\n",
       "      <td>0.150549</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.189115</td>\n",
       "      <td>0.051019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>0.096893</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.321086</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.177028</td>\n",
       "      <td>0.498502</td>\n",
       "      <td>0.685983</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.151293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287489</td>\n",
       "      <td>0.959120</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.123523</td>\n",
       "      <td>0.390410</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>-0.012968</td>\n",
       "      <td>0.170581</td>\n",
       "      <td>-0.023389</td>\n",
       "      <td>0.207278</td>\n",
       "      <td>0.177028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659123</td>\n",
       "      <td>0.521984</td>\n",
       "      <td>0.553695</td>\n",
       "      <td>0.557775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.238853</td>\n",
       "      <td>0.206718</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.472468</td>\n",
       "      <td>0.434926</td>\n",
       "      <td>0.503053</td>\n",
       "      <td>0.394309</td>\n",
       "      <td>0.499316</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.236702</td>\n",
       "      <td>0.556936</td>\n",
       "      <td>0.498502</td>\n",
       "      <td>0.659123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883121</td>\n",
       "      <td>0.831135</td>\n",
       "      <td>0.602641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248133</td>\n",
       "      <td>0.590210</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.565541</td>\n",
       "      <td>0.865809</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.815573</td>\n",
       "      <td>0.510223</td>\n",
       "      <td>0.687382</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>0.050080</td>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.302418</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.685983</td>\n",
       "      <td>0.521984</td>\n",
       "      <td>0.883121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>0.500667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299879</td>\n",
       "      <td>0.729565</td>\n",
       "      <td>0.675987</td>\n",
       "      <td>0.448822</td>\n",
       "      <td>0.754968</td>\n",
       "      <td>0.884103</td>\n",
       "      <td>0.861323</td>\n",
       "      <td>0.409464</td>\n",
       "      <td>0.514930</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>0.044158</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.293464</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.553695</td>\n",
       "      <td>0.831135</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.462497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292752</td>\n",
       "      <td>0.855923</td>\n",
       "      <td>0.809630</td>\n",
       "      <td>0.452753</td>\n",
       "      <td>0.667454</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.910155</td>\n",
       "      <td>0.375744</td>\n",
       "      <td>0.368661</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>-0.022114</td>\n",
       "      <td>0.147741</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>0.183027</td>\n",
       "      <td>0.151293</td>\n",
       "      <td>0.557775</td>\n",
       "      <td>0.602641</td>\n",
       "      <td>0.500667</td>\n",
       "      <td>0.462497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090651</td>\n",
       "      <td>0.219169</td>\n",
       "      <td>0.177193</td>\n",
       "      <td>0.426675</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>0.433721</td>\n",
       "      <td>0.430297</td>\n",
       "      <td>0.699826</td>\n",
       "      <td>0.438413</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>-0.052511</td>\n",
       "      <td>-0.311631</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>-0.261477</td>\n",
       "      <td>-0.283110</td>\n",
       "      <td>0.584792</td>\n",
       "      <td>0.565369</td>\n",
       "      <td>0.336783</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>0.479921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051269</td>\n",
       "      <td>-0.205151</td>\n",
       "      <td>-0.231854</td>\n",
       "      <td>0.504942</td>\n",
       "      <td>0.458798</td>\n",
       "      <td>0.346234</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>0.334019</td>\n",
       "      <td>0.767297</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>0.143048</td>\n",
       "      <td>0.679090</td>\n",
       "      <td>0.275869</td>\n",
       "      <td>0.691765</td>\n",
       "      <td>0.732562</td>\n",
       "      <td>0.301467</td>\n",
       "      <td>0.497473</td>\n",
       "      <td>0.631925</td>\n",
       "      <td>0.698050</td>\n",
       "      <td>0.303379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194799</td>\n",
       "      <td>0.719684</td>\n",
       "      <td>0.751548</td>\n",
       "      <td>0.141919</td>\n",
       "      <td>0.287103</td>\n",
       "      <td>0.380585</td>\n",
       "      <td>0.531062</td>\n",
       "      <td>0.094543</td>\n",
       "      <td>0.049559</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>-0.007526</td>\n",
       "      <td>-0.097317</td>\n",
       "      <td>0.386358</td>\n",
       "      <td>-0.086761</td>\n",
       "      <td>-0.066280</td>\n",
       "      <td>0.068406</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>0.076218</td>\n",
       "      <td>0.021480</td>\n",
       "      <td>0.128053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409003</td>\n",
       "      <td>-0.102242</td>\n",
       "      <td>-0.083195</td>\n",
       "      <td>-0.073658</td>\n",
       "      <td>-0.092439</td>\n",
       "      <td>-0.068956</td>\n",
       "      <td>-0.119638</td>\n",
       "      <td>-0.128215</td>\n",
       "      <td>-0.045655</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>0.137331</td>\n",
       "      <td>0.674172</td>\n",
       "      <td>0.281673</td>\n",
       "      <td>0.693135</td>\n",
       "      <td>0.726628</td>\n",
       "      <td>0.296092</td>\n",
       "      <td>0.548905</td>\n",
       "      <td>0.660391</td>\n",
       "      <td>0.710650</td>\n",
       "      <td>0.313893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200371</td>\n",
       "      <td>0.721031</td>\n",
       "      <td>0.730713</td>\n",
       "      <td>0.130054</td>\n",
       "      <td>0.341919</td>\n",
       "      <td>0.418899</td>\n",
       "      <td>0.554897</td>\n",
       "      <td>0.109930</td>\n",
       "      <td>0.085433</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>0.177742</td>\n",
       "      <td>0.735864</td>\n",
       "      <td>0.259845</td>\n",
       "      <td>0.744983</td>\n",
       "      <td>0.800086</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.455653</td>\n",
       "      <td>0.617427</td>\n",
       "      <td>0.690299</td>\n",
       "      <td>0.223970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196497</td>\n",
       "      <td>0.761213</td>\n",
       "      <td>0.811408</td>\n",
       "      <td>0.125389</td>\n",
       "      <td>0.283257</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>0.538166</td>\n",
       "      <td>0.074126</td>\n",
       "      <td>0.017539</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>0.096781</td>\n",
       "      <td>-0.222600</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>-0.202694</td>\n",
       "      <td>-0.166777</td>\n",
       "      <td>0.332375</td>\n",
       "      <td>0.135299</td>\n",
       "      <td>0.098564</td>\n",
       "      <td>0.027653</td>\n",
       "      <td>0.187321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074743</td>\n",
       "      <td>-0.217304</td>\n",
       "      <td>-0.182195</td>\n",
       "      <td>0.314457</td>\n",
       "      <td>-0.055558</td>\n",
       "      <td>-0.058298</td>\n",
       "      <td>-0.102007</td>\n",
       "      <td>-0.107342</td>\n",
       "      <td>0.101480</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>0.033961</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.191975</td>\n",
       "      <td>0.250744</td>\n",
       "      <td>0.212583</td>\n",
       "      <td>0.318943</td>\n",
       "      <td>0.738722</td>\n",
       "      <td>0.670279</td>\n",
       "      <td>0.490424</td>\n",
       "      <td>0.421659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143003</td>\n",
       "      <td>0.260516</td>\n",
       "      <td>0.199371</td>\n",
       "      <td>0.227394</td>\n",
       "      <td>0.678780</td>\n",
       "      <td>0.639147</td>\n",
       "      <td>0.483208</td>\n",
       "      <td>0.277878</td>\n",
       "      <td>0.590973</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>0.055239</td>\n",
       "      <td>0.194204</td>\n",
       "      <td>0.143293</td>\n",
       "      <td>0.228082</td>\n",
       "      <td>0.207660</td>\n",
       "      <td>0.248396</td>\n",
       "      <td>0.570517</td>\n",
       "      <td>0.691270</td>\n",
       "      <td>0.439167</td>\n",
       "      <td>0.342627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100241</td>\n",
       "      <td>0.226680</td>\n",
       "      <td>0.188353</td>\n",
       "      <td>0.168481</td>\n",
       "      <td>0.484858</td>\n",
       "      <td>0.662564</td>\n",
       "      <td>0.440472</td>\n",
       "      <td>0.197788</td>\n",
       "      <td>0.439329</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>0.078768</td>\n",
       "      <td>0.376169</td>\n",
       "      <td>0.163851</td>\n",
       "      <td>0.407217</td>\n",
       "      <td>0.372320</td>\n",
       "      <td>0.380676</td>\n",
       "      <td>0.642262</td>\n",
       "      <td>0.683260</td>\n",
       "      <td>0.615634</td>\n",
       "      <td>0.393298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086741</td>\n",
       "      <td>0.394999</td>\n",
       "      <td>0.342271</td>\n",
       "      <td>0.215351</td>\n",
       "      <td>0.452888</td>\n",
       "      <td>0.549592</td>\n",
       "      <td>0.602450</td>\n",
       "      <td>0.143116</td>\n",
       "      <td>0.310655</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>-0.017306</td>\n",
       "      <td>-0.104321</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>-0.081629</td>\n",
       "      <td>-0.072497</td>\n",
       "      <td>0.200774</td>\n",
       "      <td>0.229977</td>\n",
       "      <td>0.178009</td>\n",
       "      <td>0.095351</td>\n",
       "      <td>0.449137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077473</td>\n",
       "      <td>-0.103753</td>\n",
       "      <td>-0.110343</td>\n",
       "      <td>-0.012662</td>\n",
       "      <td>0.060255</td>\n",
       "      <td>0.037119</td>\n",
       "      <td>-0.030413</td>\n",
       "      <td>0.389402</td>\n",
       "      <td>0.078079</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>0.025725</td>\n",
       "      <td>-0.042641</td>\n",
       "      <td>0.054458</td>\n",
       "      <td>-0.005523</td>\n",
       "      <td>-0.019887</td>\n",
       "      <td>0.283607</td>\n",
       "      <td>0.507318</td>\n",
       "      <td>0.449301</td>\n",
       "      <td>0.257584</td>\n",
       "      <td>0.331786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003195</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.022736</td>\n",
       "      <td>0.170568</td>\n",
       "      <td>0.390159</td>\n",
       "      <td>0.379975</td>\n",
       "      <td>0.215204</td>\n",
       "      <td>0.111094</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>0.082405</td>\n",
       "      <td>0.969539</td>\n",
       "      <td>0.352573</td>\n",
       "      <td>0.969476</td>\n",
       "      <td>0.962746</td>\n",
       "      <td>0.213120</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.688236</td>\n",
       "      <td>0.830318</td>\n",
       "      <td>0.185728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359921</td>\n",
       "      <td>0.993708</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.216574</td>\n",
       "      <td>0.475820</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.787424</td>\n",
       "      <td>0.243529</td>\n",
       "      <td>0.093492</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>0.064720</td>\n",
       "      <td>0.297008</td>\n",
       "      <td>0.912045</td>\n",
       "      <td>0.303038</td>\n",
       "      <td>0.287489</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.248133</td>\n",
       "      <td>0.299879</td>\n",
       "      <td>0.292752</td>\n",
       "      <td>0.090651</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.365098</td>\n",
       "      <td>0.345842</td>\n",
       "      <td>0.225429</td>\n",
       "      <td>0.360832</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>0.359755</td>\n",
       "      <td>0.233027</td>\n",
       "      <td>0.219122</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>0.079986</td>\n",
       "      <td>0.965137</td>\n",
       "      <td>0.358040</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>0.959120</td>\n",
       "      <td>0.238853</td>\n",
       "      <td>0.590210</td>\n",
       "      <td>0.729565</td>\n",
       "      <td>0.855923</td>\n",
       "      <td>0.219169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.236775</td>\n",
       "      <td>0.529408</td>\n",
       "      <td>0.618344</td>\n",
       "      <td>0.816322</td>\n",
       "      <td>0.269493</td>\n",
       "      <td>0.138957</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>0.107187</td>\n",
       "      <td>0.941082</td>\n",
       "      <td>0.343546</td>\n",
       "      <td>0.941550</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.206718</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.675987</td>\n",
       "      <td>0.809630</td>\n",
       "      <td>0.177193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345842</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209145</td>\n",
       "      <td>0.438296</td>\n",
       "      <td>0.543331</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>0.209146</td>\n",
       "      <td>0.079647</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.119616</td>\n",
       "      <td>0.077503</td>\n",
       "      <td>0.150549</td>\n",
       "      <td>0.123523</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.565541</td>\n",
       "      <td>0.448822</td>\n",
       "      <td>0.452753</td>\n",
       "      <td>0.426675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225429</td>\n",
       "      <td>0.236775</td>\n",
       "      <td>0.209145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.568187</td>\n",
       "      <td>0.518523</td>\n",
       "      <td>0.547691</td>\n",
       "      <td>0.493838</td>\n",
       "      <td>0.617624</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>-0.002968</td>\n",
       "      <td>0.413463</td>\n",
       "      <td>0.277830</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.390410</td>\n",
       "      <td>0.472468</td>\n",
       "      <td>0.865809</td>\n",
       "      <td>0.754968</td>\n",
       "      <td>0.667454</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360832</td>\n",
       "      <td>0.529408</td>\n",
       "      <td>0.438296</td>\n",
       "      <td>0.568187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892261</td>\n",
       "      <td>0.801080</td>\n",
       "      <td>0.614441</td>\n",
       "      <td>0.810455</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>0.023203</td>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.301025</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.434926</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.884103</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.433721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>0.618344</td>\n",
       "      <td>0.543331</td>\n",
       "      <td>0.518523</td>\n",
       "      <td>0.892261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855434</td>\n",
       "      <td>0.532520</td>\n",
       "      <td>0.686511</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>0.035174</td>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.295316</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.503053</td>\n",
       "      <td>0.815573</td>\n",
       "      <td>0.861323</td>\n",
       "      <td>0.910155</td>\n",
       "      <td>0.430297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359755</td>\n",
       "      <td>0.816322</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>0.547691</td>\n",
       "      <td>0.801080</td>\n",
       "      <td>0.855434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502528</td>\n",
       "      <td>0.511114</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>-0.044224</td>\n",
       "      <td>0.163953</td>\n",
       "      <td>0.105008</td>\n",
       "      <td>0.189115</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.394309</td>\n",
       "      <td>0.510223</td>\n",
       "      <td>0.409464</td>\n",
       "      <td>0.375744</td>\n",
       "      <td>0.699826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233027</td>\n",
       "      <td>0.269493</td>\n",
       "      <td>0.209146</td>\n",
       "      <td>0.493838</td>\n",
       "      <td>0.614441</td>\n",
       "      <td>0.532520</td>\n",
       "      <td>0.502528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.537848</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>-0.029866</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>0.051019</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.499316</td>\n",
       "      <td>0.687382</td>\n",
       "      <td>0.514930</td>\n",
       "      <td>0.368661</td>\n",
       "      <td>0.438413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219122</td>\n",
       "      <td>0.138957</td>\n",
       "      <td>0.079647</td>\n",
       "      <td>0.617624</td>\n",
       "      <td>0.810455</td>\n",
       "      <td>0.686511</td>\n",
       "      <td>0.511114</td>\n",
       "      <td>0.537848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id  radius_mean  texture_mean  perimeter_mean  \\\n",
       "id                       1.000000     0.074626      0.099770        0.073159   \n",
       "radius_mean              0.074626     1.000000      0.323782        0.997855   \n",
       "texture_mean             0.099770     0.323782      1.000000        0.329533   \n",
       "perimeter_mean           0.073159     0.997855      0.329533        1.000000   \n",
       "area_mean                0.096893     0.987357      0.321086        0.986507   \n",
       "smoothness_mean         -0.012968     0.170581     -0.023389        0.207278   \n",
       "compactness_mean         0.000096     0.506124      0.236702        0.556936   \n",
       "concavity_mean           0.050080     0.676764      0.302418        0.716136   \n",
       "concave points_mean      0.044158     0.822529      0.293464        0.850977   \n",
       "symmetry_mean           -0.022114     0.147741      0.071401        0.183027   \n",
       "fractal_dimension_mean  -0.052511    -0.311631     -0.076437       -0.261477   \n",
       "radius_se                0.143048     0.679090      0.275869        0.691765   \n",
       "texture_se              -0.007526    -0.097317      0.386358       -0.086761   \n",
       "perimeter_se             0.137331     0.674172      0.281673        0.693135   \n",
       "area_se                  0.177742     0.735864      0.259845        0.744983   \n",
       "smoothness_se            0.096781    -0.222600      0.006614       -0.202694   \n",
       "compactness_se           0.033961     0.206000      0.191975        0.250744   \n",
       "concavity_se             0.055239     0.194204      0.143293        0.228082   \n",
       "concave points_se        0.078768     0.376169      0.163851        0.407217   \n",
       "symmetry_se             -0.017306    -0.104321      0.009127       -0.081629   \n",
       "fractal_dimension_se     0.025725    -0.042641      0.054458       -0.005523   \n",
       "radius_worst             0.082405     0.969539      0.352573        0.969476   \n",
       "texture_worst            0.064720     0.297008      0.912045        0.303038   \n",
       "perimeter_worst          0.079986     0.965137      0.358040        0.970387   \n",
       "area_worst               0.107187     0.941082      0.343546        0.941550   \n",
       "smoothness_worst         0.010338     0.119616      0.077503        0.150549   \n",
       "compactness_worst       -0.002968     0.413463      0.277830        0.455774   \n",
       "concavity_worst          0.023203     0.526911      0.301025        0.563879   \n",
       "concave points_worst     0.035174     0.744214      0.295316        0.771241   \n",
       "symmetry_worst          -0.044224     0.163953      0.105008        0.189115   \n",
       "fractal_dimension_worst -0.029866     0.007066      0.119205        0.051019   \n",
       "Unnamed: 32                   NaN          NaN           NaN             NaN   \n",
       "\n",
       "                         area_mean  smoothness_mean  compactness_mean  \\\n",
       "id                        0.096893        -0.012968          0.000096   \n",
       "radius_mean               0.987357         0.170581          0.506124   \n",
       "texture_mean              0.321086        -0.023389          0.236702   \n",
       "perimeter_mean            0.986507         0.207278          0.556936   \n",
       "area_mean                 1.000000         0.177028          0.498502   \n",
       "smoothness_mean           0.177028         1.000000          0.659123   \n",
       "compactness_mean          0.498502         0.659123          1.000000   \n",
       "concavity_mean            0.685983         0.521984          0.883121   \n",
       "concave points_mean       0.823269         0.553695          0.831135   \n",
       "symmetry_mean             0.151293         0.557775          0.602641   \n",
       "fractal_dimension_mean   -0.283110         0.584792          0.565369   \n",
       "radius_se                 0.732562         0.301467          0.497473   \n",
       "texture_se               -0.066280         0.068406          0.046205   \n",
       "perimeter_se              0.726628         0.296092          0.548905   \n",
       "area_se                   0.800086         0.246552          0.455653   \n",
       "smoothness_se            -0.166777         0.332375          0.135299   \n",
       "compactness_se            0.212583         0.318943          0.738722   \n",
       "concavity_se              0.207660         0.248396          0.570517   \n",
       "concave points_se         0.372320         0.380676          0.642262   \n",
       "symmetry_se              -0.072497         0.200774          0.229977   \n",
       "fractal_dimension_se     -0.019887         0.283607          0.507318   \n",
       "radius_worst              0.962746         0.213120          0.535315   \n",
       "texture_worst             0.287489         0.036072          0.248133   \n",
       "perimeter_worst           0.959120         0.238853          0.590210   \n",
       "area_worst                0.959213         0.206718          0.509604   \n",
       "smoothness_worst          0.123523         0.805324          0.565541   \n",
       "compactness_worst         0.390410         0.472468          0.865809   \n",
       "concavity_worst           0.512606         0.434926          0.816275   \n",
       "concave points_worst      0.722017         0.503053          0.815573   \n",
       "symmetry_worst            0.143570         0.394309          0.510223   \n",
       "fractal_dimension_worst   0.003738         0.499316          0.687382   \n",
       "Unnamed: 32                    NaN              NaN               NaN   \n",
       "\n",
       "                         concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "id                             0.050080             0.044158      -0.022114   \n",
       "radius_mean                    0.676764             0.822529       0.147741   \n",
       "texture_mean                   0.302418             0.293464       0.071401   \n",
       "perimeter_mean                 0.716136             0.850977       0.183027   \n",
       "area_mean                      0.685983             0.823269       0.151293   \n",
       "smoothness_mean                0.521984             0.553695       0.557775   \n",
       "compactness_mean               0.883121             0.831135       0.602641   \n",
       "concavity_mean                 1.000000             0.921391       0.500667   \n",
       "concave points_mean            0.921391             1.000000       0.462497   \n",
       "symmetry_mean                  0.500667             0.462497       1.000000   \n",
       "fractal_dimension_mean         0.336783             0.166917       0.479921   \n",
       "radius_se                      0.631925             0.698050       0.303379   \n",
       "texture_se                     0.076218             0.021480       0.128053   \n",
       "perimeter_se                   0.660391             0.710650       0.313893   \n",
       "area_se                        0.617427             0.690299       0.223970   \n",
       "smoothness_se                  0.098564             0.027653       0.187321   \n",
       "compactness_se                 0.670279             0.490424       0.421659   \n",
       "concavity_se                   0.691270             0.439167       0.342627   \n",
       "concave points_se              0.683260             0.615634       0.393298   \n",
       "symmetry_se                    0.178009             0.095351       0.449137   \n",
       "fractal_dimension_se           0.449301             0.257584       0.331786   \n",
       "radius_worst                   0.688236             0.830318       0.185728   \n",
       "texture_worst                  0.299879             0.292752       0.090651   \n",
       "perimeter_worst                0.729565             0.855923       0.219169   \n",
       "area_worst                     0.675987             0.809630       0.177193   \n",
       "smoothness_worst               0.448822             0.452753       0.426675   \n",
       "compactness_worst              0.754968             0.667454       0.473200   \n",
       "concavity_worst                0.884103             0.752399       0.433721   \n",
       "concave points_worst           0.861323             0.910155       0.430297   \n",
       "symmetry_worst                 0.409464             0.375744       0.699826   \n",
       "fractal_dimension_worst        0.514930             0.368661       0.438413   \n",
       "Unnamed: 32                         NaN                  NaN            NaN   \n",
       "\n",
       "                         ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "id                       ...       0.064720         0.079986    0.107187   \n",
       "radius_mean              ...       0.297008         0.965137    0.941082   \n",
       "texture_mean             ...       0.912045         0.358040    0.343546   \n",
       "perimeter_mean           ...       0.303038         0.970387    0.941550   \n",
       "area_mean                ...       0.287489         0.959120    0.959213   \n",
       "smoothness_mean          ...       0.036072         0.238853    0.206718   \n",
       "compactness_mean         ...       0.248133         0.590210    0.509604   \n",
       "concavity_mean           ...       0.299879         0.729565    0.675987   \n",
       "concave points_mean      ...       0.292752         0.855923    0.809630   \n",
       "symmetry_mean            ...       0.090651         0.219169    0.177193   \n",
       "fractal_dimension_mean   ...      -0.051269        -0.205151   -0.231854   \n",
       "radius_se                ...       0.194799         0.719684    0.751548   \n",
       "texture_se               ...       0.409003        -0.102242   -0.083195   \n",
       "perimeter_se             ...       0.200371         0.721031    0.730713   \n",
       "area_se                  ...       0.196497         0.761213    0.811408   \n",
       "smoothness_se            ...      -0.074743        -0.217304   -0.182195   \n",
       "compactness_se           ...       0.143003         0.260516    0.199371   \n",
       "concavity_se             ...       0.100241         0.226680    0.188353   \n",
       "concave points_se        ...       0.086741         0.394999    0.342271   \n",
       "symmetry_se              ...      -0.077473        -0.103753   -0.110343   \n",
       "fractal_dimension_se     ...      -0.003195        -0.001000   -0.022736   \n",
       "radius_worst             ...       0.359921         0.993708    0.984015   \n",
       "texture_worst            ...       1.000000         0.365098    0.345842   \n",
       "perimeter_worst          ...       0.365098         1.000000    0.977578   \n",
       "area_worst               ...       0.345842         0.977578    1.000000   \n",
       "smoothness_worst         ...       0.225429         0.236775    0.209145   \n",
       "compactness_worst        ...       0.360832         0.529408    0.438296   \n",
       "concavity_worst          ...       0.368366         0.618344    0.543331   \n",
       "concave points_worst     ...       0.359755         0.816322    0.747419   \n",
       "symmetry_worst           ...       0.233027         0.269493    0.209146   \n",
       "fractal_dimension_worst  ...       0.219122         0.138957    0.079647   \n",
       "Unnamed: 32              ...            NaN              NaN         NaN   \n",
       "\n",
       "                         smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "id                               0.010338          -0.002968         0.023203   \n",
       "radius_mean                      0.119616           0.413463         0.526911   \n",
       "texture_mean                     0.077503           0.277830         0.301025   \n",
       "perimeter_mean                   0.150549           0.455774         0.563879   \n",
       "area_mean                        0.123523           0.390410         0.512606   \n",
       "smoothness_mean                  0.805324           0.472468         0.434926   \n",
       "compactness_mean                 0.565541           0.865809         0.816275   \n",
       "concavity_mean                   0.448822           0.754968         0.884103   \n",
       "concave points_mean              0.452753           0.667454         0.752399   \n",
       "symmetry_mean                    0.426675           0.473200         0.433721   \n",
       "fractal_dimension_mean           0.504942           0.458798         0.346234   \n",
       "radius_se                        0.141919           0.287103         0.380585   \n",
       "texture_se                      -0.073658          -0.092439        -0.068956   \n",
       "perimeter_se                     0.130054           0.341919         0.418899   \n",
       "area_se                          0.125389           0.283257         0.385100   \n",
       "smoothness_se                    0.314457          -0.055558        -0.058298   \n",
       "compactness_se                   0.227394           0.678780         0.639147   \n",
       "concavity_se                     0.168481           0.484858         0.662564   \n",
       "concave points_se                0.215351           0.452888         0.549592   \n",
       "symmetry_se                     -0.012662           0.060255         0.037119   \n",
       "fractal_dimension_se             0.170568           0.390159         0.379975   \n",
       "radius_worst                     0.216574           0.475820         0.573975   \n",
       "texture_worst                    0.225429           0.360832         0.368366   \n",
       "perimeter_worst                  0.236775           0.529408         0.618344   \n",
       "area_worst                       0.209145           0.438296         0.543331   \n",
       "smoothness_worst                 1.000000           0.568187         0.518523   \n",
       "compactness_worst                0.568187           1.000000         0.892261   \n",
       "concavity_worst                  0.518523           0.892261         1.000000   \n",
       "concave points_worst             0.547691           0.801080         0.855434   \n",
       "symmetry_worst                   0.493838           0.614441         0.532520   \n",
       "fractal_dimension_worst          0.617624           0.810455         0.686511   \n",
       "Unnamed: 32                           NaN                NaN              NaN   \n",
       "\n",
       "                         concave points_worst  symmetry_worst  \\\n",
       "id                                   0.035174       -0.044224   \n",
       "radius_mean                          0.744214        0.163953   \n",
       "texture_mean                         0.295316        0.105008   \n",
       "perimeter_mean                       0.771241        0.189115   \n",
       "area_mean                            0.722017        0.143570   \n",
       "smoothness_mean                      0.503053        0.394309   \n",
       "compactness_mean                     0.815573        0.510223   \n",
       "concavity_mean                       0.861323        0.409464   \n",
       "concave points_mean                  0.910155        0.375744   \n",
       "symmetry_mean                        0.430297        0.699826   \n",
       "fractal_dimension_mean               0.175325        0.334019   \n",
       "radius_se                            0.531062        0.094543   \n",
       "texture_se                          -0.119638       -0.128215   \n",
       "perimeter_se                         0.554897        0.109930   \n",
       "area_se                              0.538166        0.074126   \n",
       "smoothness_se                       -0.102007       -0.107342   \n",
       "compactness_se                       0.483208        0.277878   \n",
       "concavity_se                         0.440472        0.197788   \n",
       "concave points_se                    0.602450        0.143116   \n",
       "symmetry_se                         -0.030413        0.389402   \n",
       "fractal_dimension_se                 0.215204        0.111094   \n",
       "radius_worst                         0.787424        0.243529   \n",
       "texture_worst                        0.359755        0.233027   \n",
       "perimeter_worst                      0.816322        0.269493   \n",
       "area_worst                           0.747419        0.209146   \n",
       "smoothness_worst                     0.547691        0.493838   \n",
       "compactness_worst                    0.801080        0.614441   \n",
       "concavity_worst                      0.855434        0.532520   \n",
       "concave points_worst                 1.000000        0.502528   \n",
       "symmetry_worst                       0.502528        1.000000   \n",
       "fractal_dimension_worst              0.511114        0.537848   \n",
       "Unnamed: 32                               NaN             NaN   \n",
       "\n",
       "                         fractal_dimension_worst  Unnamed: 32  \n",
       "id                                     -0.029866          NaN  \n",
       "radius_mean                             0.007066          NaN  \n",
       "texture_mean                            0.119205          NaN  \n",
       "perimeter_mean                          0.051019          NaN  \n",
       "area_mean                               0.003738          NaN  \n",
       "smoothness_mean                         0.499316          NaN  \n",
       "compactness_mean                        0.687382          NaN  \n",
       "concavity_mean                          0.514930          NaN  \n",
       "concave points_mean                     0.368661          NaN  \n",
       "symmetry_mean                           0.438413          NaN  \n",
       "fractal_dimension_mean                  0.767297          NaN  \n",
       "radius_se                               0.049559          NaN  \n",
       "texture_se                             -0.045655          NaN  \n",
       "perimeter_se                            0.085433          NaN  \n",
       "area_se                                 0.017539          NaN  \n",
       "smoothness_se                           0.101480          NaN  \n",
       "compactness_se                          0.590973          NaN  \n",
       "concavity_se                            0.439329          NaN  \n",
       "concave points_se                       0.310655          NaN  \n",
       "symmetry_se                             0.078079          NaN  \n",
       "fractal_dimension_se                    0.591328          NaN  \n",
       "radius_worst                            0.093492          NaN  \n",
       "texture_worst                           0.219122          NaN  \n",
       "perimeter_worst                         0.138957          NaN  \n",
       "area_worst                              0.079647          NaN  \n",
       "smoothness_worst                        0.617624          NaN  \n",
       "compactness_worst                       0.810455          NaN  \n",
       "concavity_worst                         0.686511          NaN  \n",
       "concave points_worst                    0.511114          NaN  \n",
       "symmetry_worst                          0.537848          NaN  \n",
       "fractal_dimension_worst                 1.000000          NaN  \n",
       "Unnamed: 32                                  NaN          NaN  \n",
       "\n",
       "[32 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_csv.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_map={'B':1, 'M':0}\n",
    "breast_cancer_csv['diagnosis']= breast_cancer_csv['diagnosis'].map(diagnosis_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Omwx5vVbYKeo"
   },
   "source": [
    "### 3. Logistic Regression Model\n",
    "\n",
    "#### 3.1 Use Logistic Regression\n",
    "\n",
    "Use Logistic Regression and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "95    0\n",
       "96    1\n",
       "97    1\n",
       "98    1\n",
       "99    0\n",
       "Name: diagnosis, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=breast_cancer_csv['diagnosis']\n",
    "y.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=breast_cancer_csv.drop(['diagnosis', 'id', 'Unnamed: 32'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1\n",
      " 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 1\n",
      " 0 1 1 0 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 0 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 1 1 0\n",
      " 1 1 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1\n",
      " 0 0 1 0 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1\n",
      " 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1\n",
      " 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0\n",
      " 0 1 1 1 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0\n",
      " 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1]\n",
      "(398,)\n"
     ]
    }
   ],
   "source": [
    "y_trainpred= model.predict(X_train)\n",
    "print(y_trainpred[:])\n",
    "print(y_trainpred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0\n",
      " 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0\n",
      " 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1]\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "y_testpred= model.predict(X_test)\n",
    "print(y_testpred[:])\n",
    "print(y_testpred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score= accuracy_score(y_train, y_trainpred)\n",
    "#score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.935672514619883\n"
     ]
    }
   ],
   "source": [
    "scoret= accuracy_score(y_test, y_testpred)\n",
    "print('Accuracy is:',scoret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935672514619883"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "scoretm= metrics.accuracy_score(y_test, y_testpred)\n",
    "scoretm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91        63\n",
      "           1       0.95      0.94      0.95       108\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.93      0.93      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_testpred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\");\n",
    "print(classification_report(y_test, y_testpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mogg_w8vYKep"
   },
   "source": [
    "### 4. Support Vector Machine\n",
    "\n",
    "#### 4.1 Use Support Vector Machine\n",
    "\n",
    "Use Support Vector Machine and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a svm classifier\n",
    "clf= svm.SVC(kernel='linear')\n",
    "#train the model using the training sets \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#predict for test\n",
    "y_svmpred = clf.predict(X_test)\n",
    "print(y_svmpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.935672514619883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93        63\n",
      "           1       0.95      0.98      0.96       108\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.96      0.94      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ac = accuracy_score(y_test, y_testpred)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test, y_svmpred)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\");\n",
    "print(classification_report(y_test, y_svmpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdzQkTb7YKeq"
   },
   "source": [
    "### 4. Naive Bayes\n",
    "#### 4.1 Use Naive Bayes\n",
    "\n",
    "Use Naive Bayes and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb= GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gnbpred = gnb.predict(X_test)\n",
    "y_gnbpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', metrics.accuracy_score(y_test, y_gnbpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoGxthaeYKer"
   },
   "source": [
    "### 6 Gridsearch optimal parameters for all three models.\n",
    "\n",
    "Is there any difference between accuracy score of Logistic Regression and SVM? Use grid serach to find optimal parameter for both these models.\n",
    "\n",
    "> Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. Typical examples include C, kernel and gamma for Support Vector Classifier, alpha for Lasso, etc.\n",
    "\n",
    "> It is possible and recommended to search the hyper-parameter space for the best cross validation score.\n",
    "\n",
    "> https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "\n",
    "**Note:** It'll take time to execute this. After running the cell, wait for result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UeqrbsyNYKes"
   },
   "source": [
    "#### 6.1 Find Best Estimator For Logistic Regression \n",
    "\n",
    "Find out how these parameters effect model. Find out the best estimator, score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:40:29.397881Z",
     "start_time": "2019-05-09T05:40:29.392602Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UkQ9RBQZYKet"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.4s finished\n",
      "C:\\Users\\monic\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 10, 100], 'penalty': ['l1', 'l2']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_params = {\n",
    "    'penalty': ['l1','l2'],\n",
    "    'C': [1, 10, 100]\n",
    "}\n",
    "lr_gs = GridSearchCV(LogisticRegression(), lr_params, cv=5, verbose=1)\n",
    "lr_gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l2'}\n",
      "0.947290793355069\n"
     ]
    }
   ],
   "source": [
    "best_svc = lr_gs.best_estimator_\n",
    "print(lr_gs.best_params_)\n",
    "print(lr_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:23:14.036840Z",
     "start_time": "2019-05-09T05:23:14.032847Z"
    },
    "colab_type": "text",
    "id": "ioLgY3bxYKev"
   },
   "source": [
    "#### 6.2 Find Best Estimator For SVM\n",
    "\n",
    "Find out how these parameters effect model. Find out the best estimator, score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:40:31.617090Z",
     "start_time": "2019-05-09T05:40:31.612996Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vgi61VpWYKew"
   },
   "outputs": [],
   "source": [
    "svc_params = {\n",
    "    'C': [1, 10, 100],\n",
    "    'gamma': [0.001, 0.0001],\n",
    "    'kernel': ['linear','rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:23:59.157703Z",
     "start_time": "2019-05-09T05:23:59.153713Z"
    },
    "colab_type": "text",
    "id": "HrS04DfuYKez"
   },
   "source": [
    "#### 6.3 Plot the ROC curve for the SVM, Logistic Regressions and Naive Bayes on the same plot\n",
    "\n",
    "Find out which model performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:28:56.671590Z",
     "start_time": "2019-05-09T05:28:56.421258Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "q9TBM2axYKe0",
    "outputId": "8f525757-6f7f-4a8b-d154-235ae82cfdf6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c514839668>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[8,8])\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Receiver Operating Characteristic: M', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WrSrz3AAYKe3"
   },
   "source": [
    "### 6. [BONUS] Learning Curve\n",
    "\n",
    "A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much we benefit from adding more training data and whether the estimator suffers more from a variance error or a bias error. If both the validation score and the training score converge to a value that is too low with increasing size of the training set, we will not benefit much from more training data.\n",
    "\n",
    "Plot \"learning curves\" for the best models of each. This is a great way see how training/testing size affects the scores. Look at the documentation for how to use this function in sklearn.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/learning_curve.html#learning-curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'breast_cancer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-38de9dbb1cf9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[0mtarget_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'diagnosis'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m \u001b[0mfeature_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbreast_cancer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbreast_cancer_csv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'breast_cancer' is not defined"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "target_col = 'diagnosis'\n",
    "feature_cols = [c for c in breast_cancer.columns if c != target_col]\n",
    "\n",
    "X = breast_cancer_csv[feature_cols]\n",
    "y = breast_cancer_csv[target_col]\n",
    "\n",
    "title = \"Learning Curves (Logistic)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "\n",
    "estimator = LogisticRegression(C = 70.17038286703837, penalty = 'l1', solver = 'liblinear')\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "title = r\"Learning Curves (SVM, Linear kernel, $\\gamma=0.001$)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=1)\n",
    "\n",
    "estimator = SVC(C=27.825594022071257, gamma=1e-05, kernel = 'linear')\n",
    "plot_learning_curve(estimator, title, X, y, (0.7, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:22:19.657638Z",
     "start_time": "2019-05-09T05:22:19.653657Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3Zleg5E-YKe4"
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE8SgkpSYKe7"
   },
   "source": [
    "**References**\n",
    "\n",
    "[Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/downloads/breast-cancer-wisconsin-data.zip/2)\n",
    "\n",
    "[Validation curves: plotting scores to evaluate models](https://scikit-learn.org/stable/modules/learning_curve.html#learning-curves)\n",
    "\n",
    "[In-Depth: Support Vector Machines](https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html)\n",
    "\n",
    "[Understanding Support Vector Machine algorithm from examples (along with code)](https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/)\n",
    "\n",
    "[Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2019 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IOD_Lab_5_3_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
